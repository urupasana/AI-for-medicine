{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI4M_C1_W1_loss_ex_02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+yleEl2JRDHLRtX7vrL2r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urupasana/AI-for-medicine/blob/master/AI4M_C1_W1_loss_ex_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b0EQpGNvzAS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2fb9bf92-0254-436c-b4c9-d7a741164226"
      },
      "source": [
        "# Import the necessary packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvbednxNv8I3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "62e8ccd6-6d46-4672-c05e-85f36bf5acc3"
      },
      "source": [
        "# Read csv file containing training datadata\n",
        "train_df = pd.read_csv(\"nih/train-small.csv\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a85df4798e13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read csv file containing training datadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nih/train-small.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File nih/train-small.csv does not exist: 'nih/train-small.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzzIrZQ5v_fk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Count up the number of instances of each class (drop non-class columns from the counts)\n",
        "class_counts = train_df.sum().drop(['Image','PatientId'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeR0A09hwCyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for column in class_counts.keys():\n",
        "    print(f\"The class {column} has {train_df[column].sum()} samples\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nS6Mq4M1wGJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot up the distribution of counts\n",
        "sns.barplot(class_counts.values, class_counts.index, color='b')\n",
        "plt.title('Distribution of Classes for Training Dataset', fontsize=15)\n",
        "plt.xlabel('Number of Patients', fontsize=15)\n",
        "plt.ylabel('Diseases', fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv8ITSgBwJig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate an array of 4 binary label values, 3 positive and 1 negative\n",
        "y_true = np.array(\n",
        "        [[1],\n",
        "         [1],\n",
        "         [1],\n",
        "         [0]])\n",
        "print(f\"y_true: \\n{y_true}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQtxi0v8wQbl",
        "colab_type": "text"
      },
      "source": [
        "Two models\n",
        "To better understand the loss function, you will pretend that you have two models.\n",
        "\n",
        "Model 1 always outputs a 0.9 for any example that it's given.\n",
        "Model 2 always outputs a 0.1 for any example that it's given."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PqriuWAwMtL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make model predictions that are always 0.9 for all examples\n",
        "y_pred_1 = 0.9 * np.ones(y_true.shape)\n",
        "print(f\"y_pred_1: \\n{y_pred_1}\")\n",
        "print()\n",
        "y_pred_2 = 0.1 * np.ones(y_true.shape)\n",
        "print(f\"y_pred_2: \\n{y_pred_2}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK_v1xtHwXHE",
        "colab_type": "text"
      },
      "source": [
        "Problems with the regular loss function\n",
        "The learning goal here is to notice that with a regular loss function (not a weighted loss), the model that always outputs 0.9 has a smaller loss (performs better) than model 2.\n",
        "\n",
        "This is because there is a class imbalance, where 3 out of the 4 labels are 1.\n",
        "If the data were perfectly balanced, (two labels were 1, and two labels were 0), model 1 and model 2 would have the same loss. Each would get two examples correct and two examples incorrect.\n",
        "However, since the data is not balanced, the regular loss function implies that model 1 is better than model 2.\n",
        "Notice the shortcomings of a regular non-weighted loss\n",
        "See what loss you get from these two models (model 1 always predicts 0.9, and model 2 always predicts 0.1), see what the regular (unweighted) loss function is for each model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpbOILUawUP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_reg_1 = -1 * np.sum(y_true * np.log(y_pred_1)) + \\\n",
        "                -1 * np.sum((1 - y_true) * np.log(1 - y_pred_1))\n",
        "print(f\"loss_reg_1: {loss_reg_1:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azj-tGUBwbEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_reg_2 = -1 * np.sum(y_true * np.log(y_pred_2)) + \\\n",
        "                -1 * np.sum((1 - y_true) * np.log(1 - y_pred_2))\n",
        "print(f\"loss_reg_2: {loss_reg_2:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_L88_YjwdrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"When the model 1 always predicts 0.9, the regular loss is {loss_reg_1:.4f}\")\n",
        "print(f\"When the model 2 always predicts 0.1, the regular loss is {loss_reg_2:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OLV0BcJwuhF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb_lVsYWwg7m",
        "colab_type": "text"
      },
      "source": [
        "Notice that the loss function gives a greater loss when the predictions are always 0.1, because the data is imbalanced, and has three labels of 1 but only one label for 0.\n",
        "\n",
        "Given a class imbalance with more positive labels, the regular loss function implies that the model with the higher prediction of 0.9 performs better than the model with the lower prediction of 0.1\n",
        "\n",
        "How a weighted loss treats both models the same\n",
        "With a weighted loss function, you will get the same weighted loss when the predictions are all 0.9 versus when the predictions are all 0.1.\n",
        "\n",
        "Notice how a prediction of 0.9 is 0.1 away from the positive label of 1.\n",
        "Also notice how a prediction of 0.1 is 0.1 away from the negative label of 0\n",
        "So model 1 and 2 are \"symmetric\" along the midpoint of 0.5, if you plot them on a number line between 0 and 1.\n",
        "Weighted Loss Equation\n",
        "Calculate the loss for the zero-th label (column at index 0)\n",
        "\n",
        "The loss is made up of two terms. To make it easier to read the code, you will calculate each of these terms separately. We are giving each of these two terms a name for explanatory purposes, but these are not officially called losspos or lossneg\n",
        "losspos: we'll use this to refer to the loss where the actual label is positive (the positive examples).\n",
        "lossneg: we'll use this to refer to the loss where the actual label is negative (the negative examples).\n",
        "\n",
        "loss(i)=loss(i)pos+los(i)neg\n",
        "\n",
        "loss(i)pos=−1×weight(i)pos×y(i)×log(ŷ (i))\n",
        "\n",
        "loss(i)neg=−1×weight(i)neg×(1−y(i))×log(1−ŷ (i))\n",
        "\n",
        "Since this sample dataset is small enough, you can calculate the positive weight to be used in the weighted loss function. To get the positive weight, count how many NEGATIVE labels are present, divided by the total number of examples.\n",
        "\n",
        "In this case, there is one negative label, and four total examples.\n",
        "\n",
        "Similarly, the negative weight is the fraction of positive labels.\n",
        "\n",
        "Run the next cell to define positive and negative weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W70hbo0iwvxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the positive weight as the fraction of negative labels\n",
        "w_p = 1/4\n",
        "\n",
        "# calculate the negative weight as the fraction of positive labels\n",
        "w_n = 3/4\n",
        "\n",
        "print(f\"positive weight w_p: {w_p}\")\n",
        "print(f\"negative weight w_n {w_n}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txmAz8Huw08b",
        "colab_type": "text"
      },
      "source": [
        "Model 1 weighted loss\n",
        "Run the next two cells to calculate the two loss terms separately.\n",
        "\n",
        "Here, loss_1_pos and loss_1_neg are calculated using the y_pred_1 predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBKCkqaDw3-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate and print out the first term in the loss function, which we are calling 'loss_pos'\n",
        "loss_1_pos = -1 * np.sum(w_p * y_true * np.log(y_pred_1 ))\n",
        "print(f\"loss_1_pos: {loss_1_pos:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTbxSL5Ww7id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate and print out the second term in the loss function, which we're calling 'loss_neg'\n",
        "loss_1_neg = -1 * np.sum(w_n * (1 - y_true) * np.log(1 - y_pred_1 ))\n",
        "print(f\"loss_1_neg: {loss_1_neg:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON4BgRMxw-XV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sum positive and negative losses to calculate total loss\n",
        "loss_1 = loss_1_pos + loss_1_neg\n",
        "print(f\"loss_1: {loss_1:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llE94RG2xFJK",
        "colab_type": "text"
      },
      "source": [
        "Model 2 weighted loss\n",
        "Now do the same calculations for when the predictions are from `y_pred_2'. Calculate the two terms of the weighted loss function and add them together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r40P_iJaxGYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate and print out the first term in the loss function, which we are calling 'loss_pos'\n",
        "loss_2_pos = -1 * np.sum(w_p * y_true * np.log(y_pred_2))\n",
        "print(f\"loss_2_pos: {loss_2_pos:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtydlZVNxBMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate and print out the second term in the loss function, which we're calling 'loss_neg'\n",
        "loss_2_neg = -1 * np.sum(w_n * (1 - y_true) * np.log(1 - y_pred_2))\n",
        "print(f\"loss_2_neg: {loss_2_neg:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV9coeWbxLX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sum positive and negative losses to calculate total loss when the prediction is y_pred_2\n",
        "loss_2 = loss_2_pos + loss_2_neg\n",
        "print(f\"loss_2: {loss_2:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7VQSb7AxXAs",
        "colab_type": "text"
      },
      "source": [
        "Compare model 1 and model 2 weighted loss¶"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt7ZH6vSxSDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"When the model always predicts 0.9, the total loss is {loss_1:.4f}\")\n",
        "print(f\"When the model always predicts 0.1, the total loss is {loss_2:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqp2LMRdxbH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"loss_1_pos: {loss_1_pos:.4f} \\t loss_1_neg: {loss_1_neg:.4f}\")\n",
        "print()\n",
        "print(f\"loss_2_pos: {loss_2_pos:.4f} \\t loss_2_neg: {loss_2_neg:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCN-M4pixfCD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "76688a14-df66-49fa-a750-0492df52039c"
      },
      "source": [
        "# View the labels (true values) that you will practice with\n",
        "y_true = np.array(\n",
        "        [[1,0],\n",
        "         [1,0],\n",
        "         [1,0],\n",
        "         [1,0],\n",
        "         [0,1]\n",
        "        ])\n",
        "y_true"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIUPf6h7xiSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# See what happens when you set axis=0\n",
        "print(f\"using axis = 0 {np.sum(y_true,axis=0)}\")\n",
        "\n",
        "# Compare this to what happens when you set axis=1\n",
        "print(f\"using axis = 1 {np.sum(y_true,axis=1)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHLhXeP_xnUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the positive weights as the fraction of negative labels (0) for each class (each column)\n",
        "w_p = np.sum(y_true == 0,axis=0) / y_true.shape[0]\n",
        "w_p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwB5Q1wIxqfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the negative weights as the fraction of positive labels (1) for each class\n",
        "w_n = np.sum(y_true == 1, axis=0) / y_true.shape[0]\n",
        "w_n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztxSl5eOxqla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set model predictions where all predictions are the same\n",
        "y_pred = np.ones(y_true.shape)\n",
        "y_pred[:,0] = 0.3 * y_pred[:,0]\n",
        "y_pred[:,1] = 0.7 * y_pred[:,1]\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djbb4siXxyq8",
        "colab_type": "text"
      },
      "source": [
        "As before, calculate the two terms that make up the loss function. Notice that you are working with more than one class (represented by columns). In this case, there are two classes.\n",
        "\n",
        "Start by calculating the loss for class 0.\n",
        "\n",
        "loss(i)=loss(i)pos+los(i)neg\n",
        "\n",
        "loss(i)pos=−1×weight(i)pos×y(i)×log(ŷ (i))\n",
        "\n",
        "loss(i)neg=−1×weight(i)neg×(1−y(i))×log(1−ŷ (i))\n",
        "\n",
        "View the zero column for the weights, true values, and predictions that you will use to calculate the loss from the positive predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zoc9vgT7xq0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print and view column zero of the weight\n",
        "print(f\"w_p[0]: {w_p[0]}\")\n",
        "print(f\"y_true[:,0]: {y_true[:,0]}\")\n",
        "print(f\"y_pred[:,0]: {y_pred[:,0]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVabl9Gyxq28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the loss from the positive predictions, for class 0\n",
        "loss_0_pos = -1 * np.sum(w_p[0] * \n",
        "                y_true[:, 0] * \n",
        "                np.log(y_pred[:, 0])\n",
        "              )\n",
        "print(f\"loss_0_pos: {loss_0_pos:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v47jSn2Gxqw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print and view column zero of the weight\n",
        "print(f\"w_n[0]: {w_n[0]}\")\n",
        "print(f\"y_true[:,0]: {y_true[:,0]}\")\n",
        "print(f\"y_pred[:,0]: {y_pred[:,0]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIdY43KDxqib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate the loss from the negative predictions, for class 0\n",
        "loss_0_neg = -1 * np.sum( \n",
        "                w_n[0] * \n",
        "                (1 - y_true[:, 0]) * \n",
        "                np.log(1 - y_pred[:, 0])\n",
        "              )\n",
        "print(f\"loss_0_neg: {loss_0_neg:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsKiJMozxqZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add the two loss terms to get the total loss for class 0\n",
        "loss_0 = loss_0_neg + loss_0_pos\n",
        "print(f\"loss_0: {loss_0:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukZIgkQfyFUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "-- # calculate the loss from the positive predictions, for class 1\n",
        "loss_1_pos = -1 * np.sum(w_p[1] * \n",
        "                y_true[:, 1] * \n",
        "                np.log(y_pred[:, 1])\n",
        "              )\n",
        "print(f\"loss_1_pos: {loss_1_pos:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbnFFASEyFaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "-- # Calculate the loss from the negative predictions, for class 1\n",
        "loss_1_neg = -1 * np.sum( \n",
        "                w_n[1] * \n",
        "                (1 - y_true[:, 1]) * \n",
        "                np.log(1 - y_pred[:, 1])\n",
        "              )\n",
        "print(f\"loss_1_neg: {loss_1_neg:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUV1kwwUyFXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "-- # add the two loss terms to get the total loss for class 1\n",
        "loss_1 = loss_1_neg + loss_1_pos\n",
        "print(f\"loss_1: {loss_1:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_lGUzoMyFRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}